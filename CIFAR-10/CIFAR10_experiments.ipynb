{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CIFAR10 experiments.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Initially taking book's code as a reference"
      ],
      "metadata": {
        "id": "Dy7EZETaNvC-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import cifar10\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import Conv2D, BatchNormalization, MaxPooling2D, Dropout, Dense, Flatten"
      ],
      "metadata": {
        "id": "5tkI2gi5MuQb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The CIFAR10 dataset contains 60,000 color images in 10 classes, \n",
        "# with 6,000 images in each class. The dataset is divided into 50,000 training\n",
        "# images and 10,000 testing images.\n",
        "data = cifar10\n",
        "(X_train, Y_train), (X_test, Y_test) = data.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4f3oVkPrMuS-",
        "outputId": "e705615d-da35-4524-b68e-ee6decb6e30c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 13s 0us/step\n",
            "170508288/170498071 [==============================] - 13s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train= X_train.astype(\"float32\") / 255\n",
        "X_test = X_test.astype(\"float32\") / 255"
      ],
      "metadata": {
        "id": "rWl2U_GZdE9E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQveM9KfLjaB",
        "outputId": "0c603967-3333-4bfd-8583-ca355b16f978"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_7 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
            "                                                                 \n",
            " conv2d_18 (Conv2D)          (None, 30, 30, 32)        896       \n",
            "                                                                 \n",
            " batch_normalization_18 (Bat  (None, 30, 30, 32)       128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_12 (MaxPoolin  (None, 15, 15, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_19 (Conv2D)          (None, 15, 15, 64)        18496     \n",
            "                                                                 \n",
            " batch_normalization_19 (Bat  (None, 15, 15, 64)       256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_13 (MaxPoolin  (None, 7, 7, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_20 (Conv2D)          (None, 7, 7, 128)         73856     \n",
            "                                                                 \n",
            " batch_normalization_20 (Bat  (None, 7, 7, 128)        512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " flatten_6 (Flatten)         (None, 6272)              0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 10)                62730     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 156,874\n",
            "Trainable params: 156,426\n",
            "Non-trainable params: 448\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "inputs = keras.Input(shape=(32, 32, 3))\n",
        "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(inputs)\n",
        "x = layers.BatchNormalization()(x) # added\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\", padding='same')(x)\n",
        "x = layers.BatchNormalization()(x) # added\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\", padding='same')(x)\n",
        "x = layers.BatchNormalization()(x) # added\n",
        "x = layers.Flatten()(x)\n",
        "outputs = layers.Dense(10, activation=\"softmax\")(x)\n",
        "\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# NOTES:\n",
        "# Consider batch size and normalization as in the book's code\n",
        "# You can also consider padding in the Conv2D layer\n",
        "# Compare Adam optimizer and rmsprop\n",
        "# Consider batch normalization\n",
        "# Consider dropout"
      ],
      "metadata": {
        "id": "ajDh8vwRMOHd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy', optimizer=\"Adam\", metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "QcGpRGcnMOKN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train,Y_train,epochs=70,batch_size=64)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1lkU13IAOF1l",
        "outputId": "2cd01c7e-0b22-4b3d-a634-65939483e229"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/70\n",
            "782/782 [==============================] - 18s 21ms/step - loss: 1.6747 - accuracy: 0.4253\n",
            "Epoch 2/70\n",
            "782/782 [==============================] - 17s 22ms/step - loss: 1.0359 - accuracy: 0.6329\n",
            "Epoch 3/70\n",
            "782/782 [==============================] - 17s 22ms/step - loss: 0.8346 - accuracy: 0.7112\n",
            "Epoch 4/70\n",
            "782/782 [==============================] - 17s 22ms/step - loss: 0.7122 - accuracy: 0.7547\n",
            "Epoch 5/70\n",
            "782/782 [==============================] - 17s 22ms/step - loss: 0.6346 - accuracy: 0.7843\n",
            "Epoch 6/70\n",
            "782/782 [==============================] - 17s 22ms/step - loss: 0.5747 - accuracy: 0.8054\n",
            "Epoch 7/70\n",
            "782/782 [==============================] - 17s 22ms/step - loss: 0.5263 - accuracy: 0.8206\n",
            "Epoch 8/70\n",
            "782/782 [==============================] - 17s 22ms/step - loss: 0.4802 - accuracy: 0.8359\n",
            "Epoch 9/70\n",
            "782/782 [==============================] - 17s 22ms/step - loss: 0.4520 - accuracy: 0.8478\n",
            "Epoch 10/70\n",
            "782/782 [==============================] - 17s 22ms/step - loss: 0.4117 - accuracy: 0.8594\n",
            "Epoch 11/70\n",
            "782/782 [==============================] - 17s 22ms/step - loss: 0.3875 - accuracy: 0.8682\n",
            "Epoch 12/70\n",
            "782/782 [==============================] - 17s 22ms/step - loss: 0.3574 - accuracy: 0.8764\n",
            "Epoch 13/70\n",
            "782/782 [==============================] - 17s 22ms/step - loss: 0.3373 - accuracy: 0.8837\n",
            "Epoch 14/70\n",
            "782/782 [==============================] - 17s 22ms/step - loss: 0.3190 - accuracy: 0.8907\n",
            "Epoch 15/70\n",
            "782/782 [==============================] - 17s 22ms/step - loss: 0.3001 - accuracy: 0.8973\n",
            "Epoch 16/70\n",
            "782/782 [==============================] - 17s 22ms/step - loss: 0.2851 - accuracy: 0.9030\n",
            "Epoch 17/70\n",
            "782/782 [==============================] - 17s 22ms/step - loss: 0.2696 - accuracy: 0.9086\n",
            "Epoch 18/70\n",
            "782/782 [==============================] - 17s 22ms/step - loss: 0.2524 - accuracy: 0.9137\n",
            "Epoch 19/70\n",
            "782/782 [==============================] - 17s 22ms/step - loss: 0.2470 - accuracy: 0.9159\n",
            "Epoch 20/70\n",
            "782/782 [==============================] - 17s 22ms/step - loss: 0.2397 - accuracy: 0.9177\n",
            "Epoch 21/70\n",
            "782/782 [==============================] - 17s 22ms/step - loss: 0.2268 - accuracy: 0.9226\n",
            "Epoch 22/70\n",
            "782/782 [==============================] - 17s 22ms/step - loss: 0.2185 - accuracy: 0.9254\n",
            "Epoch 23/70\n",
            "782/782 [==============================] - 17s 22ms/step - loss: 0.2071 - accuracy: 0.9286\n",
            "Epoch 24/70\n",
            "782/782 [==============================] - 17s 22ms/step - loss: 0.1994 - accuracy: 0.9303\n",
            "Epoch 25/70\n",
            "782/782 [==============================] - 17s 22ms/step - loss: 0.1935 - accuracy: 0.9331\n",
            "Epoch 26/70\n",
            "782/782 [==============================] - 17s 22ms/step - loss: 0.1852 - accuracy: 0.9355\n",
            "Epoch 27/70\n",
            "782/782 [==============================] - 17s 22ms/step - loss: 0.1772 - accuracy: 0.9399\n",
            "Epoch 28/70\n",
            "782/782 [==============================] - 17s 22ms/step - loss: 0.1685 - accuracy: 0.9424\n",
            "Epoch 29/70\n",
            "782/782 [==============================] - 17s 22ms/step - loss: 0.1690 - accuracy: 0.9409\n",
            "Epoch 30/70\n",
            "782/782 [==============================] - 17s 21ms/step - loss: 0.1636 - accuracy: 0.9437\n",
            "Epoch 31/70\n",
            "782/782 [==============================] - 17s 21ms/step - loss: 0.1531 - accuracy: 0.9464\n",
            "Epoch 32/70\n",
            "782/782 [==============================] - 17s 22ms/step - loss: 0.1513 - accuracy: 0.9468\n",
            "Epoch 33/70\n",
            "782/782 [==============================] - 17s 22ms/step - loss: 0.1517 - accuracy: 0.9481\n",
            "Epoch 34/70\n",
            "782/782 [==============================] - 17s 21ms/step - loss: 0.1392 - accuracy: 0.9519\n",
            "Epoch 35/70\n",
            "782/782 [==============================] - 17s 22ms/step - loss: 0.1406 - accuracy: 0.9516\n",
            "Epoch 36/70\n",
            "782/782 [==============================] - 17s 22ms/step - loss: 0.1360 - accuracy: 0.9538\n",
            "Epoch 37/70\n",
            "782/782 [==============================] - 17s 22ms/step - loss: 0.1377 - accuracy: 0.9524\n",
            "Epoch 38/70\n",
            "782/782 [==============================] - 17s 22ms/step - loss: 0.1334 - accuracy: 0.9547\n",
            "Epoch 39/70\n",
            "782/782 [==============================] - 17s 22ms/step - loss: 0.1241 - accuracy: 0.9572\n",
            "Epoch 40/70\n",
            "782/782 [==============================] - 17s 22ms/step - loss: 0.1247 - accuracy: 0.9559\n",
            "Epoch 41/70\n",
            "782/782 [==============================] - 17s 22ms/step - loss: 0.1257 - accuracy: 0.9577\n",
            "Epoch 42/70\n",
            "782/782 [==============================] - 17s 22ms/step - loss: 0.1215 - accuracy: 0.9587\n",
            "Epoch 43/70\n",
            "782/782 [==============================] - 17s 22ms/step - loss: 0.1193 - accuracy: 0.9590\n",
            "Epoch 44/70\n",
            "782/782 [==============================] - 17s 22ms/step - loss: 0.1156 - accuracy: 0.9605\n",
            "Epoch 45/70\n",
            "782/782 [==============================] - 17s 22ms/step - loss: 0.1131 - accuracy: 0.9610\n",
            "Epoch 46/70\n",
            "782/782 [==============================] - 17s 22ms/step - loss: 0.1093 - accuracy: 0.9629\n",
            "Epoch 47/70\n",
            "782/782 [==============================] - 17s 22ms/step - loss: 0.1071 - accuracy: 0.9636\n",
            "Epoch 48/70\n",
            "782/782 [==============================] - 17s 22ms/step - loss: 0.1061 - accuracy: 0.9637\n",
            "Epoch 49/70\n",
            "782/782 [==============================] - 17s 22ms/step - loss: 0.1051 - accuracy: 0.9637\n",
            "Epoch 50/70\n",
            "782/782 [==============================] - 17s 22ms/step - loss: 0.1045 - accuracy: 0.9646\n",
            "Epoch 51/70\n",
            "782/782 [==============================] - 17s 22ms/step - loss: 0.1051 - accuracy: 0.9643\n",
            "Epoch 52/70\n",
            "782/782 [==============================] - 17s 22ms/step - loss: 0.0996 - accuracy: 0.9664\n",
            "Epoch 53/70\n",
            "782/782 [==============================] - 17s 22ms/step - loss: 0.0976 - accuracy: 0.9658\n",
            "Epoch 54/70\n",
            "782/782 [==============================] - 17s 22ms/step - loss: 0.1004 - accuracy: 0.9660\n",
            "Epoch 55/70\n",
            "782/782 [==============================] - 17s 22ms/step - loss: 0.0930 - accuracy: 0.9682\n",
            "Epoch 56/70\n",
            "782/782 [==============================] - 17s 22ms/step - loss: 0.0928 - accuracy: 0.9682\n",
            "Epoch 57/70\n",
            "782/782 [==============================] - 17s 22ms/step - loss: 0.0939 - accuracy: 0.9676\n",
            "Epoch 58/70\n",
            "782/782 [==============================] - 17s 22ms/step - loss: 0.0899 - accuracy: 0.9689\n",
            "Epoch 59/70\n",
            "782/782 [==============================] - 17s 22ms/step - loss: 0.0868 - accuracy: 0.9699\n",
            "Epoch 60/70\n",
            "782/782 [==============================] - 17s 22ms/step - loss: 0.0885 - accuracy: 0.9694\n",
            "Epoch 61/70\n",
            "782/782 [==============================] - 17s 22ms/step - loss: 0.0840 - accuracy: 0.9711\n",
            "Epoch 62/70\n",
            "782/782 [==============================] - 17s 22ms/step - loss: 0.0859 - accuracy: 0.9708\n",
            "Epoch 63/70\n",
            "782/782 [==============================] - 17s 22ms/step - loss: 0.0843 - accuracy: 0.9718\n",
            "Epoch 64/70\n",
            "782/782 [==============================] - 17s 22ms/step - loss: 0.0885 - accuracy: 0.9698\n",
            "Epoch 65/70\n",
            "782/782 [==============================] - 17s 22ms/step - loss: 0.0823 - accuracy: 0.9724\n",
            "Epoch 66/70\n",
            "782/782 [==============================] - 17s 22ms/step - loss: 0.0811 - accuracy: 0.9717\n",
            "Epoch 67/70\n",
            "782/782 [==============================] - 17s 22ms/step - loss: 0.0816 - accuracy: 0.9729\n",
            "Epoch 68/70\n",
            "782/782 [==============================] - 17s 22ms/step - loss: 0.0817 - accuracy: 0.9724\n",
            "Epoch 69/70\n",
            "782/782 [==============================] - 17s 22ms/step - loss: 0.0808 - accuracy: 0.9720\n",
            "Epoch 70/70\n",
            "782/782 [==============================] - 17s 22ms/step - loss: 0.0762 - accuracy: 0.9739\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot Model Loss and Accuracy During Training\n",
        "%matplotlib inline\n",
        "acc = history.history['accuracy']\n",
        "loss = history.history['loss']\n",
        "epochs = range(1, len(acc) + 1)\n",
        "plt.plot(epochs, acc, 'b', label='Training accuracy')\n",
        "plt.title('Training accuracy')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "plt.plot(epochs, loss, 'b', label='Training loss', color='r')\n",
        "plt.title('Training loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "id": "9RIzbjlhOP9e",
        "outputId": "2619a145-4b84-472b-f53c-a55b2f573c78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training time = 10m (6s per epoch)\n",
        "# Training acc = 89%\n",
        "\n",
        "# Graph observation: A lot of fluctuations as compared to Waleed's"
      ],
      "metadata": {
        "id": "HMZb4DAJQX3a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# EVALUATION:\n",
        "# ACCURACY = 58% [useless]\n",
        "model.evaluate(X_test,Y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "INQWxk2AOQiF",
        "outputId": "bd24466a-40ef-4f8f-c0dd-91a2195a4ced"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 2.3093 - accuracy: 0.7000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.309290885925293, 0.699999988079071]"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# When I interrputed the model at 10 epochs. It gave a test acc of 61%"
      ],
      "metadata": {
        "id": "MHjn_Fl5PBel"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**MY EXPERIMENTS**"
      ],
      "metadata": {
        "id": "athFRNt3Z5BV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiment 1:\n",
        "  # Mentioned batch_size of 64 for training\n",
        "  # Training time = 6m (3s per epoch)\n",
        "  # Training acc = 61%"
      ],
      "metadata": {
        "id": "FC1pNo_hZlq3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# EVALUATION:\n",
        "# ACCURACY = 58% [same]\n",
        "model.evaluate(X_test,Y_test)"
      ],
      "metadata": {
        "id": "80L9ZOKBeK4m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiment 1B:\n",
        "  # Reducing epochs to 50\n",
        "  # ACCURACY = 62% [useless]\n",
        "model.evaluate(X_test,Y_test)"
      ],
      "metadata": {
        "id": "G3OBA3Q9jbsu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiment 1C:\n",
        "  # rmsprop needs 20 epochs only.\n",
        "  # ACCURACY = 60% [useless]\n",
        "model.evaluate(X_test,Y_test)"
      ],
      "metadata": {
        "id": "ilt_3-s2j2TF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# QUERIES:\n",
        "  # Does rmsprop optimizer has any dependency with the model architecture, no. of layers, and batchnormalization layer\n",
        "  # Does Adam optimizer has any dependency with dropout "
      ],
      "metadata": {
        "id": "hLH4UqqzkEnR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CONCLUSION:\n",
        "# Batch size has reduced the training time by half"
      ],
      "metadata": {
        "id": "UhqnDvDnYtVR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiment 2:\n",
        "  # Continuation of Exp1 and Exp1B\n",
        "  # Adding batchnormalization after each conv2d layer\n",
        "    # Training time = 4m (4s per epoch)\n",
        "    # Training acc = 98%"
      ],
      "metadata": {
        "id": "2kk_qJrLPBhN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# EVALUATION:\n",
        "# ACCURACY = 70\n",
        "model.evaluate(X_test,Y_test)"
      ],
      "metadata": {
        "id": "WU89NJxvPBk8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiment 2B:\n",
        "  # Reducing epochs to 30"
      ],
      "metadata": {
        "id": "rvX7c1_VrTBU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# EVALUATION:\n",
        "# ACCURACY = 71\n",
        "model.evaluate(X_test,Y_test)"
      ],
      "metadata": {
        "id": "lZrFoSiXNpHn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Conclusion: We have improved the accuracy from 60 to 70% through batch normalization"
      ],
      "metadata": {
        "id": "CVz-gJY9OmXP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Slow internet connection"
      ],
      "metadata": {
        "id": "a8WUDgQQgWW3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiment 3:\n",
        "  # Continuation of Exp2\n",
        "  # Normalize the data and convert data-type to float\n",
        "    # Training time = 3m (4s per epoch)\n",
        "    # Training acc = 97%"
      ],
      "metadata": {
        "id": "vOluFRDCqZKN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# EVALUATION:\n",
        "# ACCURACY = 70\n",
        "model.evaluate(X_test,Y_test)"
      ],
      "metadata": {
        "id": "7ynya--QfEeo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Conclusion: no effect on acc by experiment 3"
      ],
      "metadata": {
        "id": "AP4Np3XXn0fb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiment 4:\n",
        "  # Continuation of Exp3\n",
        "  # Converted padding type to 'same' in the last two Conv2D layers\n",
        "    # Training time = 3m (4s per epoch)\n",
        "    # Training acc = 98%"
      ],
      "metadata": {
        "id": "2MxIduL9hGrZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# EVALUATION:\n",
        "# ACCURACY = 70\n",
        "model.evaluate(X_test,Y_test)"
      ],
      "metadata": {
        "id": "sKCQ08lZhGtt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiment 5:\n",
        "  # Continuation of Exp4\n",
        "  # \"Changing the positions of Max Pooling layers\"\n",
        "    # Training time = 5m (7s per epoch)\n",
        "    # Training acc = 98%"
      ],
      "metadata": {
        "id": "TkIiW8xwhGv2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**BETTER MODEL**"
      ],
      "metadata": {
        "id": "_MF1FWzMMuDp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "inputs = keras.Input(shape=(32, 32, 3))\n",
        "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(inputs)\n",
        "x = layers.BatchNormalization()(x)      # added\n",
        "                                        # removed Max Pooling\n",
        "x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\", padding='same')(x)\n",
        "x = layers.BatchNormalization()(x)      # added\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\", padding='same')(x)\n",
        "x = layers.BatchNormalization()(x)      # added\n",
        "x = layers.MaxPooling2D(pool_size=2)(x) # added\n",
        "x = layers.Dropout(0.5)(x)              # added\n",
        "x = layers.Flatten()(x)\n",
        "outputs = layers.Dense(10, activation=\"softmax\")(x)\n",
        "\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "#model.summary()"
      ],
      "metadata": {
        "id": "eYMNPo2ijTJs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# EVALUATION:\n",
        "# ACCURACY = 73\n",
        "model.evaluate(X_test,Y_test)"
      ],
      "metadata": {
        "id": "byVy3fCflr0x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiment 5B:\n",
        "    # Removing one more Max Pooling layer (the upper one)\n",
        "    # Training time = 7m (11s per epoch)\n",
        "    # Training acc = 98%"
      ],
      "metadata": {
        "id": "5iOCORlBjTMC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# EVALUATION:\n",
        "# ACCURACY = 67 [useless]\n",
        "model.evaluate(X_test,Y_test)"
      ],
      "metadata": {
        "id": "xhiTKoockTxw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiment 6:\n",
        "    # Introducing dropout\n",
        "  # Continuation of Exp5 orig\n",
        "    # Training time = 5m (7s per epoch)\n",
        "    # Training acc ="
      ],
      "metadata": {
        "id": "tHk7Vr4_kT0J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dropout has changed the curve a lot. Great!\n",
        "# Lets try more epochs = 50\n",
        "    # Training time = 13m (7s per epoch)\n",
        "    # Training acc = 95%"
      ],
      "metadata": {
        "id": "KEuyTH1arvY2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# EVALUATION:\n",
        "# ACCURACY = 80 [Good improvement]\n",
        "model.evaluate(X_test,Y_test)"
      ],
      "metadata": {
        "id": "tIsAbvdTwFpo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Conclusion: We have improved the accuracy from 73 to 80% through dropout"
      ],
      "metadata": {
        "id": "931bsADnPkrm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets try more epochs = 100\n",
        "    # Training time = 7m (7s per epoch)\n",
        "    # Training acc = 92%"
      ],
      "metadata": {
        "id": "-OdCGKfSwOgo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# EVALUATION:\n",
        "# ACCURACY = 80\n",
        "model.evaluate(X_test,Y_test)"
      ],
      "metadata": {
        "id": "cpj7YWxT6J1v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Conclusion: 50 epochs are enough with dropout"
      ],
      "metadata": {
        "id": "ILx-xBCxM7iL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiment 7:\n",
        "  # Removing all batch_normalization layers\n",
        "    # Training time =  (6s per epoch)\n",
        "    # Training acc = 89%\n",
        "\n",
        "# EVALUATION:\n",
        "# ACCURACY = 79\n",
        "model.evaluate(X_test,Y_test)"
      ],
      "metadata": {
        "id": "w02aRulmNzlQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Conslusion: Don't remove batch_normalization layers"
      ],
      "metadata": {
        "id": "v4RStMa-ViWm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Try 100 epochs then pull it back to 50\n",
        "    # Training time =  10m (6s per epoch)\n",
        "    # Training acc = 92%\n",
        "\n",
        "# EVALUATION:\n",
        "# ACCURACY = 78.4 [useless]\n",
        "model.evaluate(X_test,Y_test)"
      ],
      "metadata": {
        "id": "lP-3e_yyR3UN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiment 8:\n",
        "  # Adding one dropout layer of 0.4\n",
        "    # Training time = (7s per epoch)\n",
        "    # Training acc = 84%\n",
        "\n",
        "# EVALUATION:\n",
        "# ACCURACY = 76%\n",
        "model.evaluate(X_test,Y_test)"
      ],
      "metadata": {
        "id": "n2osaZTLOC7Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Conclusion: One dropout layer is enough\n",
        "# Removing the last added layer"
      ],
      "metadata": {
        "id": "qZu78E1lYdXR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiment 9:\n",
        "  # Big changes: Added 03 Conv2D layers (one in each set)\n",
        "    # Training time = 10m (12s per epoch)\n",
        "    # Training acc = 97%\n",
        "\n",
        "# EVALUATION:\n",
        "# ACCURACY = 82.6%\n",
        "model.evaluate(X_test,Y_test)"
      ],
      "metadata": {
        "id": "hPzsVrUIVni0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Another Model**"
      ],
      "metadata": {
        "id": "pSzohO_jZS9B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "inputs = keras.Input(shape=(32, 32, 3))\n",
        "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(inputs)\n",
        "x = layers.BatchNormalization()(x)      # added\n",
        "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\", padding='same')(x)\n",
        "x = layers.BatchNormalization()(x)      # added\n",
        "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\", padding='same')(x)\n",
        "x = layers.BatchNormalization()(x)      # added\n",
        "                                        # removed Max Pooling\n",
        "x = layers.Dropout(0.3)(x)              # added\n",
        "\n",
        "x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\", padding='same')(x)\n",
        "x = layers.BatchNormalization()(x)      # added\n",
        "x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\", padding='same')(x)\n",
        "x = layers.BatchNormalization()(x)      # added\n",
        "x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\", padding='same')(x)\n",
        "x = layers.BatchNormalization()(x)      # added\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Dropout(0.4)(x)              # added\n",
        "\n",
        "x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\", padding='same')(x)\n",
        "x = layers.BatchNormalization()(x)      # added\n",
        "x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\", padding='same')(x)\n",
        "x = layers.BatchNormalization()(x)      # added\n",
        "x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\", padding='same')(x)\n",
        "x = layers.BatchNormalization()(x)      # added\n",
        "x = layers.MaxPooling2D(pool_size=2)(x) # added\n",
        "x = layers.Dropout(0.5)(x)              # added\n",
        "\n",
        "x = layers.Flatten()(x)\n",
        "outputs = layers.Dense(10, activation=\"softmax\")(x)\n",
        "\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "jR21tHNrZPFS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiment 10:\n",
        "  # Adding 02 more dropout layer as in the waleed's code\n",
        "    # Training time =  10m (13s per epoch)\n",
        "    # Training acc = 92%\n",
        "\n",
        "# EVALUATION:\n",
        "# ACCURACY = 85.2%\n",
        "model.evaluate(X_test,Y_test)"
      ],
      "metadata": {
        "id": "AGmrIGf4ZPHl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# NICE IMPROVEMENT! with 03 dropout layer"
      ],
      "metadata": {
        "id": "5LY8V6ylhuwU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiment 11:\n",
        "  # Adding batch normalization layer in between each set of Conv2D layers as in the waleed's code\n",
        "    # Training time = 12m (16s per epoch)\n",
        "    # Training acc = 93\n",
        "\n",
        "# EVALUATION:\n",
        "# ACCURACY = 86.4%\n",
        "model.evaluate(X_test,Y_test)"
      ],
      "metadata": {
        "id": "_-frNdO4VnlL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NOTE:**"
      ],
      "metadata": {
        "id": "DqVyPEleqyBo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) WARNING:\n",
        "  # Consider type of padding in the first Conv2D layer"
      ],
      "metadata": {
        "id": "PanHLEFLiXDR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2) CONSIDER:\n",
        "  # Batch_size"
      ],
      "metadata": {
        "id": "db4p3p_Cg_nS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now compare the no. of CNN nodes with your MNIST or CatsDogs code\n",
        "  # We can add a dense layer of our choice ----- done\n",
        "  # We will change the last Conv2D layer nodes to 256 ----- done\n",
        "  # Then we will add one, one Conv2D layer in each set ----- done"
      ],
      "metadata": {
        "id": "PlZU0Q-pqI0n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Last work: Play with wrong predicitons"
      ],
      "metadata": {
        "id": "3QHffkUgqJWn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiment 12:\n",
        "  # Changed the last Conv2D layer nodes to 256\n",
        "    # Training time = 13m (16s per epoch)\n",
        "    # Training acc = 93\n",
        "    # Conclusion: By seeing the graph, I think we can improve acc by giving more epochs \n",
        "\n",
        "# EVALUATION:\n",
        "# ACCURACY = 84.0% [lower]\n",
        "model.evaluate(X_test,Y_test)"
      ],
      "metadata": {
        "id": "crdxmTAUqJY1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiment 13:\n",
        "  # Continuation of Exp 11\n",
        "  # Adding one, one, Conv2D layer in each set\n",
        "    # Training time = 19m (21s per epoch)\n",
        "    # Training acc = 96\n",
        "    # Conclusion: Maybe more epochs would be better\n",
        "\n",
        "# EVALUATION:\n",
        "# ACCURACY = 85.7% [lower]\n",
        "model.evaluate(X_test,Y_test)"
      ],
      "metadata": {
        "id": "3rkzfKyhwAJe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiment 14:\n",
        "  # Continuation of Exp 13\n",
        "  # Adding dense layer of 128 after flatten\n",
        "    # Training time = 19m (21s per epoch)\n",
        "    # Training acc = 95\n",
        "\n",
        "# EVALUATION:\n",
        "# ACCURACY = 88.4%\n",
        "model.evaluate(X_test,Y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kUmUMlSC1b0C",
        "outputId": "80e0f7ff-0357-403a-d14d-5835c3bc757c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 2s 6ms/step - loss: 0.4241 - accuracy: 0.8839\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.424057275056839, 0.883899986743927]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **THE BEST MODEL**"
      ],
      "metadata": {
        "id": "m0G0HNQnPge9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "inputs = keras.Input(shape=(32, 32, 3))\n",
        "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(inputs)\n",
        "x = layers.BatchNormalization()(x)      \n",
        "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\", padding='same')(x)\n",
        "x = layers.BatchNormalization()(x)      \n",
        "  # removed MaxPooling                                        \n",
        "x = layers.Dropout(0.2)(x)             \n",
        "\n",
        "x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\", padding='same')(x)\n",
        "x = layers.BatchNormalization()(x)      \n",
        "x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\", padding='same')(x)\n",
        "x = layers.BatchNormalization()(x)      \n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Dropout(0.3)(x)         \n",
        "\n",
        "x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\", padding='same')(x)\n",
        "x = layers.BatchNormalization()(x)   \n",
        "x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\", padding='same')(x)\n",
        "x = layers.BatchNormalization()(x)   \n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Dropout(0.4)(x)\n",
        "\n",
        "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\", padding='same')(x)\n",
        "x = layers.BatchNormalization()(x)   \n",
        "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\", padding='same')(x)\n",
        "x = layers.BatchNormalization()(x)   \n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Dropout(0.5)(x)     \n",
        "\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dense(128, activation='relu')(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.Dropout(0.5)(x)              # added\n",
        "outputs = layers.Dense(10, activation=\"softmax\")(x)\n",
        "\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "92xdZKuW2S5-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiment 15:\n",
        "  # Continuation of Exp 14\n",
        "  # Set two Conv2D layers in each set\n",
        "    # Training time = 12m (15s per epoch)\n",
        "    # Training acc = 92\n",
        "\n",
        "# EVALUATION:\n",
        "# ACCURACY = 86.5%\n",
        "model.evaluate(X_test,Y_test)"
      ],
      "metadata": {
        "id": "FcE9CcH8e6Zu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiment 16:\n",
        "  # Continuation of Exp 15\n",
        "  # Add a set of 256 Conv2D\n",
        "    # Training time =  (17s per epoch)\n",
        "    # Training acc = 97\n",
        "    # OBSERVATION: Final dimensions after CNN operation is 3 by 3.\n",
        "\n",
        "# EVALUATION:\n",
        "# ACCURACY = 89.2% [best]\n",
        "model.evaluate(X_test,Y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48GQSqq5jD81",
        "outputId": "5e7b3de7-2dfa-4ce4-832e-cb84a7817d62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 2s 5ms/step - loss: 0.4285 - accuracy: 0.8918\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.42845094203948975, 0.8917999863624573]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Congratulations! You beat the record"
      ],
      "metadata": {
        "id": "Zc0TqOQJoaO3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets try 70 epochs with batch_size = 128\n",
        "    # Training time = 18m (15s per epoch)\n",
        "    # Training acc = 97\n",
        "\n",
        "# EVALUATION:\n",
        "# ACCURACY = 88%\n",
        "model.evaluate(X_test,Y_test)"
      ],
      "metadata": {
        "id": "j0pdOVurosFf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiment 17:\n",
        "  # Continuation of Exp 16\n",
        "  # Adding one more dense layer of 256 nodes above 128's.\n",
        "  # Pull Epochs back to 50, batch_size = 128\n",
        "    # Training time = 13m (15s per epoch)\n",
        "    # Training acc = 97\n",
        "\n",
        "# EVALUATION:\n",
        "# ACCURACY = 88.8%\n",
        "model.evaluate(X_test,Y_test)"
      ],
      "metadata": {
        "id": "2E0tDOS8t3aZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets try batch_size = 64\n",
        "    # Training time = (17s per epoch)\n",
        "    # Training acc = 97\n",
        "\n",
        "# EVALUATION:\n",
        "# ACCURACY = 88.6%\n",
        "model.evaluate(X_test,Y_test)"
      ],
      "metadata": {
        "id": "ESz0InJqvmPG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiment 18:\n",
        "  # Delete 256 dense layer. Batch_size = 64, set same padding for the first CNN layer.\n",
        "  # Now you have only one hidden dense layer of 128. \n",
        "\n",
        "# EVALUATION:\n",
        "# ACCURACY = 89.07%\n",
        "model.evaluate(X_test,Y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eK5F-sFI6iK8",
        "outputId": "29e3270e-8217-472d-a293-ee7591704307"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 2s 6ms/step - loss: 0.4348 - accuracy: 0.8907\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.43483662605285645, 0.8906999826431274]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Conclusion:\n",
        "  # No use of same padding in the first layer"
      ],
      "metadata": {
        "id": "M8lw5l5oBXGi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# THE BEST MODEL:\n",
        "  # Remove the same padding in the first layer\n",
        "  # Epoch = 70\n",
        "    # Training time = 20m (17s per epoch)\n",
        "    # Training acc = 97\n",
        "\n",
        "# EVALUATION:\n",
        "# ACCURACY = 89.3%\n",
        "model.evaluate(X_test,Y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kV-hduaeBmtN",
        "outputId": "a2fee3b5-19c9-4c3f-d9d3-23a7d53fac3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 2s 5ms/step - loss: 0.4492 - accuracy: 0.8926\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.449187695980072, 0.8925999999046326]"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# NOTE: You can also try 50 epochs\n",
        "# 50 epochs will probably give an accuracy 89.2%"
      ],
      "metadata": {
        "id": "2lNw2hRmPrrm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**THE END**"
      ],
      "metadata": {
        "id": "JFBQPfsd3fz0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Refer experiment-notebook in which we PLAYED WITH WRONG PREDICTIONS"
      ],
      "metadata": {
        "id": "ewvxVwKH2S-q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}